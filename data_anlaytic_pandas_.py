# -*- coding: utf-8 -*-
"""Data Anlaytic PANDAS .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MmEZposg6qeKeIVwbCiOWFK6MDXuLrrO
"""

import pandas as pd
data_set = pd.read_csv("datasets.csv")
data_set.head()

"""data_set.head() = It gives first 5 data from data set"""

data_set.dtypes

"""dtypes = attribute of data ;
object is both number and char
"""

data_set.tail()

""".tail() = last 5 data from data set"""

mumbai_data = data_set.copy()

"""copy() making an copy of dataframe in variable name mumbai_data"""

mumbai_data.info()

""".info() -> it give info about dataset"""

mumbai_data.isna()

""".isna() = which value is null (FALSE -> NOT NULL , TRUE -> IS NULL)"""

mumbai_data.isna().sum()

""".sum() -> gives sum of empty cell in that column"""

mumbai_data.loc[10]

""".loc() -> to get data from specific location in the pandas the number starts from 0 so in above example we got data of row 9"""

mumbai_data.loc[10:12]

mumbai_data["categoryName"]

"""in above example we can get information of specific columns."""

mumbai_data[["about","categoryName"]]

"""Now, for 2 column details we gave 2 square brackets .. because its related to array.. example in array form we can write {my_array=["about","categoryName"] mumbai_array = my_array} all this command are equal to above command  """

mumbai_data[["about","categoryName"]].loc[13]

"""from above command we can get both rows and column specification .. like specific row and column

from below example we put same rows and we got data from 10 to 12 column data
"""

mumbai_data[["about","categoryName"]].loc[10:12]

"""now from below examples we will how we can get sum of null values of specific rows and columns"""

mumbai_data[["about","categoryName"]].loc[13].isna().sum()

mumbai_data[["about","categoryName"]].loc[10:12].isna().sum()

mumbai_data_subset = mumbai_data[["about","categoryName","link"]]
mumbai_data_subset.head()

"""In above code we basically made new subset of given dataset and in this subset we only included 3 columns which can be seen above

## **REMOVING ROWS & COLUMNS**
"""

mumbai_data.drop(3)

mumbai_data.head()

""".drop() -> helps in deleting row and that column .. but we need to tell panda that we are permentatly deleting that row and column .

There are 2 ways to do permenantly delet this row and column
"""

mumbai_data_delet = mumbai_data.drop(3)
mumbai_data_delet.head()

mumbai_data.drop(mumbai_data.index[[3, 4]], inplace=True)
mumbai_data.head()

"""To drop specific column we need to do (column = "")"""

mumbai_data.drop(columns="about")

mumbai_data.drop(columns=["about","categoryName"])

"""so, after doing all this if new data set needed without any changes then we can re write the begining code

"""

mumbai_data = pd.read_csv("datasets.csv")
mumbai_data.head()

"""**CONDITONS TO PERFORM OPERATION ON DATASET**"""

mumbai_data["about"]

"""

---


this command is checking if both the side written in command are equal

---
eg: If take crime_data then command will be crime_data [crime_data["*column_name* type]=="THEFT"] in this we will see if that column is  == to THEFT and data will be displed in true or false .. if such thing is not there then nothing will be appeard
"""

mumbai_data[mumbai_data["about"] == "Global Climate Data Since 1929"]

mumbai_data["about"] == "Global Climate Data Since 1929"

mumbai_data[mumbai_data["categoryName"] == "Biology"]

mumbai_data.dtypes

mumbai_data["categoryName"].dtypes

mumbai_data[mumbai_data["categoryName"]==True]

"""**TWO CONDITIONS**

*   OR operators
*   AND operators

AND OPERATOR
using AND operator means satisfying 2 condition **&** is used has symbol of AND in python
"""

(2==2) & (2>0)

mumbai_data[(mumbai_data["categoryName"] =="Biology") & (mumbai_data["cloud"]== "GitHub" )]

"""**OR Operator**
-> In or operator we check atleast one operation is true and symbole(|)
"""

(2==2) |(2 <0)

mumbai_data[(mumbai_data["categoryName"] =="Biology") | (mumbai_data["cloud"]== "GitHub" )]

"""**LESS THEN OR EQUAL TO (<=) & MORE THEN OR EQUAL TO (=>)**"""

mumbai_data.head()

mumbai_data.dtypes

mumbai_data[(mumbai_data["vintage"] >= 2020) | (mumbai_data["vintage"] <= 2020)]

"""so in above example we got result of less then

**NOT EQUAL TO**
we are finding value which is not equal to some other value !=
"""

mumbai_data[(mumbai_data["vintage"] != 2020)]

"""**The isin() Method**
-> isin helps to full fil more than 2 conditions in easiest manner

mumbai_data[(mumbai_data["categoryName"] == "Biology")|(mumabi_data["categoryName"] == "Healthcare") | (mumbai_data["categoryName"] == "Data Challenges") ] we can write all this in easiest manner using **.isin** method
mumbai_data[mumbai_data["categoryName"] .isin(["Biology","Healthcare","Data Challenges"]) ]
"""

mumbai_data[mumbai_data["categoryName"] .isin(["Biology","Healthcare","Data Challenges"]) ]

"""mumbai_data = ["Biology","Healthcare","Data Challenges"]
mumbai_data[mumbai_data["categoryName"].isin("category_column")]
We can also do like this method

mumbai_data[(mumbai_data["categoryName"].isin(["Biology", "Healthcare", "Data Challenges"])) & (mumbai_data["cloud"] == "GitHub")]
one more method with AND opertion

**The isna() Method**
-> isna where we are only display where value is null the answer is in True and False mostly
"""

import pandas as pd
mumbai_data = pd.read_csv("datasets.csv")
mumbai_data[mumbai_data["vintage"].isna()]

